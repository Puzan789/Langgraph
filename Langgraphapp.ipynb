{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"]= os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\LangGraph\\venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "d:\\LangGraph\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build index\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "#load\n",
    "docs=[WebBaseLoader(url).load() for url in urls]\n",
    "docs_list=[item for sublist in docs for item in sublist]\n",
    "\n",
    "# Split \n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder( # Bpe tokenizer\n",
    "    chunk_size=500,chunk_overlap=0\n",
    ")\n",
    "doc_splits=text_splitter.split_documents(docs_list)\n",
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever=vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s=[\n",
    "#     [1,2,3],[4,5,6],[7,8,9]\n",
    "# ]\n",
    "# q=[l for m in s for l in m]\n",
    "# q\n",
    "# [1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROUTER\n",
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel,Field\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    #Routes a query to the most relvant datasource\n",
    "    datasource: Literal[\"vectorstore\",\"wiki_search\"]=Field(\n",
    "        ...,#it means field is required#ellipsis\n",
    "        description=\"Given a user question choose to route it to wikipedia or a vectorstore.\"\n",
    "\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma2-9b-It\")\n",
    "structured_llm_router=llm.with_structured_output(RouteQuery) # it will search whether the vector search or wiki search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt \n",
    "system='''you are an expert at routing user question to vectprstore or wikipedia.\n",
    "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use wiki-search.\n",
    "'''\n",
    "route_prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system),\n",
    "        (\"human\",\"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router=route_prompt | structured_llm_router\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasource='wiki_search'\n",
      "datasource='vectorstore'\n"
     ]
    }
   ],
   "source": [
    "print(question_router.invoke({\n",
    "    \"question\": \"Who is DR sanduk ruit\"\n",
    "}))\n",
    "\n",
    "print(question_router.invoke({\n",
    "    \"question\": \"What is prompt engineering?\"\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieval Grader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"retrieval grader\" is crucial for ensuring the relevance of retrieved documents to the user's question. It filters out irrelevant or erroneous results before generating an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Binary check on relvance checkon retrieved documents\"\"\"\n",
    "    binary_score: str =Field(\n",
    "        description=\"Documents are Relevant to the question 'yes' or 'no' \"\n",
    "    )\n",
    "\n",
    "# prompt \n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "grade_prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\",\"Retrieved  document : \\n \\n {document} \\n \\n User question :{question}\")\n",
    "])\n",
    "structured_llm_grader=llm.with_structured_output(GradeDocuments)\n",
    "retreival_grader=grade_prompt | structured_llm_grader\n",
    "question=\"Who is sharukhan\"\n",
    "docs=retriever.get_relevant_documents(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "doc_txt=docs[1].page_content\n",
    "\n",
    "print(retreival_grader.invoke({\n",
    "    \"document\": doc_txt,\n",
    "    \"question\": question\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
